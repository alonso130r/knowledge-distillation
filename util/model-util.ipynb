{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors.torch import save_file\n",
    "import torch\n",
    "from typing import List\n",
    "\n",
    "def save_logits(logits : List[torch.tensor], file_path : str) -> None:\n",
    "    \"\"\"\n",
    "    Save a list of output logits\n",
    "\n",
    "    Parameters:\n",
    "    - logits (List[torch.tensor]): list of the logits you want to save\n",
    "    - file_path (str): location to store the logits\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    for i, logit in enumerate(logits):\n",
    "        data[f\"Question {i+1}\"] = logit.to('cpu')\n",
    "\n",
    "    save_file(data, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors.torch import safe_open\n",
    "\n",
    "def load_list_of_logits_safetensor(file_path: str):\n",
    "    \"\"\"\n",
    "    Load a list of saved torch logits\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): file path for where to look for the logits file\n",
    "    \"\"\"\n",
    "    with safe_open(file_path, framework=\"pt\") as f:\n",
    "        logits_list = []\n",
    "        for key in f.keys():\n",
    "            logits_list.append(f.get_tensor(key))\n",
    "    \n",
    "    return logits_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class KnowledgeDistillationLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Object used to calculate KD loss using a mix of hard loss (cross-entropy) and soft loss (KL-Divergence).\n",
    "    \"\"\"\n",
    "    def __init__(self, temperature=1.0, alpha=0.5):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        - temperature (float): Temperature for softening logits before KL-Divergence.\n",
    "        - alpha (float): Weight for combining hard and soft losses.\n",
    "        \"\"\"\n",
    "        super(KnowledgeDistillationLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, student_logits, teacher_logits, labels):\n",
    "\n",
    "        # Hard Loss: Cross-Entropy between student predictions and true labels\n",
    "        loss_hard = self.criterion(student_logits, labels)\n",
    "\n",
    "        # Soft Loss: KL-Divergence between soft targets from teacher and student\n",
    "        teacher_probs = F.softmax(teacher_logits / self.temperature, dim=1)\n",
    "        student_log_probs = F.log_softmax(student_logits / self.temperature, dim=1)\n",
    "        loss_soft = F.kl_div(student_log_probs, teacher_probs, reduction='batchmean', log_target=False) * (self.temperature ** 2)\n",
    "\n",
    "        # Combine the losses\n",
    "        loss = self.alpha * loss_hard + (1.0 - self.alpha) * loss_soft\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from safetensors.torch import save_file\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "def save_model_safetensors_sharded(model: AutoModelForCausalLM, save_directory: str, max_shard_size: int = 5 * 1024 * 1024 * 1024, dtype: str = \"FP32\"):\n",
    "    \"\"\"\n",
    "    Save a model in a sharded SafeTensors format with a maximum shard size.\n",
    "\n",
    "    Parameters:\n",
    "    - model (PreTrainedModel): The model to save.\n",
    "    - save_directory (str): The directory where the shards will be saved.\n",
    "    - max_shard_size (int): Maximum shard size in bytes. Default is 5GB.\n",
    "    - dtype (str): The data type to use when saving the tensors. Options are 'FP32', 'BF16', 'FP16'. Default is 'FP32'.\n",
    "    \"\"\"\n",
    "    # Ensure the save directory exists\n",
    "    os.makedirs(save_directory, exist_ok=True)\n",
    "    \n",
    "    # Convert model to state dict\n",
    "    state_dict = model.state_dict()\n",
    "\n",
    "    # Initialize shard variables\n",
    "    shard = {}\n",
    "    current_shard_size = 0\n",
    "    shard_index = 0\n",
    "\n",
    "    # Map the dtype string to a PyTorch dtype\n",
    "    dtype_map = {\n",
    "        \"FP32\": torch.float32,\n",
    "        \"BF16\": torch.bfloat16,\n",
    "        \"FP16\": torch.float16,\n",
    "    }\n",
    "\n",
    "    selected_dtype = dtype_map[dtype]\n",
    "\n",
    "    for key, tensor in state_dict.items():\n",
    "        # Convert tensor to the selected dtype\n",
    "        tensor = tensor.to(selected_dtype)\n",
    "\n",
    "        tensor_size = tensor.numel() * tensor.element_size()\n",
    "        \n",
    "        # If adding this tensor would exceed the max_shard_size, save the current shard\n",
    "        if current_shard_size + tensor_size > max_shard_size and shard:\n",
    "            shard_file = os.path.join(save_directory, f\"model-{shard_index:05d}-of-unknown.safetensors\")\n",
    "            save_file(shard, shard_file)\n",
    "            shard_index += 1\n",
    "            shard = {}\n",
    "            current_shard_size = 0\n",
    "        \n",
    "        # Add tensor to current shard\n",
    "        shard[key] = tensor\n",
    "        current_shard_size += tensor_size\n",
    "\n",
    "    # Save the final shard\n",
    "    if shard:\n",
    "        shard_file = os.path.join(save_directory, f\"model-{shard_index:05d}-of-unknown.safetensors\")\n",
    "        save_file(shard, shard_file)\n",
    "        shard_index += 1\n",
    "\n",
    "    # Rename files to reflect the total number of shards\n",
    "    total_shards = shard_index\n",
    "    for i in range(total_shards):\n",
    "        old_name = os.path.join(save_directory, f\"model-{i:05d}-of-unknown.safetensors\")\n",
    "        new_name = os.path.join(save_directory, f\"model-{i+1:05d}-of-{total_shards:05d}.safetensors\")\n",
    "        os.rename(old_name, new_name)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
