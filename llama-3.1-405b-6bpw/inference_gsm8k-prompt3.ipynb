{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from exllamav2 import ExLlamaV2, ExLlamaV2Config, ExLlamaV2Tokenizer, ExLlamaV2Cache_Q6\n",
    "# from exllamav2 import ExLlamaV2_HF\n",
    "# from transformers import AutoTokenizer\n",
    "import torch\n",
    "from safetensors.torch import save_file\n",
    "from datasets import load_dataset\n",
    "from typing import List\n",
    "import gc\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)\n",
    "num_gpus = torch.cuda.device_count()\n",
    "# devices = [torch.device(\"cuda:0\"), torch.device(\"cuda:1\"), torch.device(\"cuda:2\"), torch.device(\"cuda:3\")]\n",
    "devices = [\"cuda:0\", \"cuda:1\", \"cuda:2\", \"cuda:3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0 can access GPU 1: True\n",
      "GPU 0 can access GPU 2: True\n",
      "GPU 0 can access GPU 3: True\n",
      "GPU 1 can access GPU 0: True\n",
      "GPU 1 can access GPU 2: True\n",
      "GPU 1 can access GPU 3: True\n",
      "GPU 2 can access GPU 0: True\n",
      "GPU 2 can access GPU 1: True\n",
      "GPU 2 can access GPU 3: True\n",
      "GPU 3 can access GPU 0: True\n",
      "GPU 3 can access GPU 1: True\n",
      "GPU 3 can access GPU 2: True\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_gpus):\n",
    "        for j in range(num_gpus):\n",
    "            if i != j:\n",
    "                can_access = torch.cuda.can_device_access_peer(i, j)\n",
    "                print(f\"GPU {i} can access GPU {j}: {can_access}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ExLlamaV2Config()\n",
    "config.model_dir = \"./llama-405b/models--ek826--Meta-Llama-3.1-405B-Instruct-6.0bpw-exl2/snapshots/c3aafe6600c3c081f514e33ea325da7a19cb1822\"\n",
    "config.prepare()\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"./llama-405b/models--ek826--Meta-Llama-3.1-405B-Instruct-6.0bpw-exl2/snapshots/c3aafe6600c3c081f514e33ea325da7a19cb1822\")\n",
    "model = ExLlamaV2(config)\n",
    "tokenizer = ExLlamaV2Tokenizer(config)\n",
    "cache = ExLlamaV2Cache_Q6(model, lazy = True)\n",
    "model.load_autosplit(cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "prompt = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "264bc4c5a42741bba8dce3d0b1279c81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/7.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9520bb382a4425a87da8df32aa865bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e5af2671606431f87015a7f7f2d69d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/419k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a217c8c31e7e4eeb880935cb691421de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/7473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9765ef13a30e49b9b973241dbbe8cbd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1319 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = load_dataset(\"openai/gsm8k\", \"main\", split=\"train\")\n",
    "questions = ds[\"question\"]\n",
    "questions = questions[:2638]\n",
    "prompt = \"(At the end of the question) Briefly double-check that your answer is correct once done. \"\n",
    "questions = [prompt + question for question in questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(At the end of the question) Briefly double-check that your answer is correct once done. Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logits(inputs : str) -> torch.tensor:\n",
    "    inputs = tokenizer.encode(inputs)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.forward(inputs)\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_logits(logits : List[torch.tensor], ) -> None:\n",
    "    data = {}\n",
    "    for i, logit in enumerate(logits):\n",
    "        data[f\"Question {i+1}\"] = logit.to('cpu')\n",
    "\n",
    "    save_file(data, \"llama-3.1-405b-gsm8k-reverse-KL-prompt-tensors.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be used later on to load back the logits\n",
    "\n",
    "from safetensors.torch import safe_open\n",
    "\n",
    "def load_list_of_logits_safetensor(file_path):\n",
    "    # Open the safetensor file\n",
    "    with safe_open(file_path, framework=\"pt\") as f:\n",
    "        logits_list = []\n",
    "        for key in f.keys():\n",
    "            logits_list.append(f.get_tensor(key))\n",
    "    \n",
    "    return logits_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit1 = get_logits(questions[0]).to('cpu')\n",
    "save_logits(logit1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf3288772c543b6ba15977d31a6d353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2638 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logits = [get_logits(question).to('cpu') for question in tqdm(questions)]\n",
    "save_logits(logits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
