{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)\n",
    "datapath = \"../data/24.csv\"\n",
    "instructions = \"Using only basic arithmetic operations (BEDMAS, excluding exponents), solve the following puzzle using the numbers provided to get the result 24\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vijaygoyal/anaconda3/envs/mps/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/Users/vijaygoyal/anaconda3/envs/mps/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# student model\n",
    "student_tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2-large\")\n",
    "student_model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50258, 1280)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "student_model.resize_token_embeddings(len(student_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(datapath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "puzzles = df['Puzzles'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game24Dataset(Dataset):\n",
    "    def __init__(self, puzzles, tokenizer, instructions, max_length=512):\n",
    "        self.puzzles = puzzles\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.instructions = instructions\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.puzzles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        puzzle = self.puzzles[idx]\n",
    "        prompt = f\"{self.instructions}: {puzzle}\"\n",
    "        encoding = self.tokenizer(\n",
    "            prompt,\n",
    "            add_special_tokens=True,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids = encoding['input_ids'].squeeze()\n",
    "        attention_mask = encoding['attention_mask'].squeeze()\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': input_ids\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prototype of a loss function\n",
    "\n",
    "def enhanced_loss_function(outputs, puzzles, tokenizer):\n",
    "    total_loss = 0\n",
    "    batch_size = len(puzzles)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        solution = tokenizer.decode(outputs[i], skip_special_tokens=True)\n",
    "        puzzle = puzzles[i]\n",
    "        \n",
    "        # Check for correctness\n",
    "        correct, partial_loss = evaluate_solution(solution, puzzle)\n",
    "        \n",
    "        total_loss += partial_loss if not correct else 0\n",
    "    \n",
    "    return total_loss / batch_size\n",
    "\n",
    "def evaluate_solution(solution, puzzle):\n",
    "   # Extract numbers and operators from the solution\n",
    "    numbers = re.findall(r'\\d+', solution)\n",
    "    operators_and_brackets = re.findall(r'[+\\-*/()]', solution)\n",
    "    \n",
    "    # Ensure the numbers used are exactly the ones in the puzzle\n",
    "    puzzle_numbers = sorted(puzzle.split())\n",
    "    solution_numbers = sorted(numbers)\n",
    "    \n",
    "    # Calculate a partial loss based on the incorrect use of numbers\n",
    "    partial_loss = len(set(puzzle_numbers) - set(solution_numbers)) / len(puzzle_numbers)\n",
    "    \n",
    "    if puzzle_numbers != solution_numbers:\n",
    "        return False, 1 + partial_loss\n",
    "    \n",
    "    # Check if valid operators and brackets are used\n",
    "    valid_operators = set('+-*/')\n",
    "    valid_brackets = set('()')\n",
    "    invalid_chars = [char for char in operators_and_brackets if char not in valid_operators and char not in valid_brackets]\n",
    "    \n",
    "    if invalid_chars:\n",
    "        partial_loss += 0.5  # Arbitrary penalty for invalid operators or brackets\n",
    "    \n",
    "    # Check for balanced brackets\n",
    "    if not are_brackets_balanced(solution):\n",
    "        partial_loss += 0.5  # Arbitrary penalty for unbalanced brackets\n",
    "    \n",
    "    # Evaluate the expression\n",
    "    try:\n",
    "        result = eval(solution)\n",
    "        if result == 24:\n",
    "            return True, 0\n",
    "        else:\n",
    "            return False, abs(24 - result) / 24 + partial_loss\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating solution: {e}\")\n",
    "        return False, 1 + partial_loss \n",
    "\n",
    "def are_brackets_balanced(expression):\n",
    "    stack = []\n",
    "    brackets = {'(': ')'}\n",
    "    \n",
    "    for char in expression:\n",
    "        if char in brackets.keys():\n",
    "            stack.append(char)\n",
    "        elif char in brackets.values():\n",
    "            if not stack or brackets[stack.pop()] != char:\n",
    "                return False\n",
    "    return not stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Game24Dataset(puzzles, student_tokenizer, instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 1280)\n",
       "    (wpe): Embedding(1024, 1280)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-35): 36 x GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1280, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, tokenizer):\n",
    "    total_correct = 0\n",
    "    total_puzzles = 0\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Generate solutions from the model\n",
    "            generated_outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Decode puzzles for evaluation\n",
    "        puzzles = [tokenizer.decode(ids, skip_special_tokens=True).replace(instructions, \"\").strip() for ids in input_ids]\n",
    "        \n",
    "        for i in range(len(generated_outputs)):\n",
    "            solution = tokenizer.decode(generated_outputs[i], skip_special_tokens=True)\n",
    "            puzzle = puzzles[i]\n",
    "            correct, _ = evaluate_solution(solution, puzzle)\n",
    "            total_correct += int(correct)\n",
    "            total_puzzles += 1\n",
    "    \n",
    "    accuracy = total_correct / total_puzzles if total_puzzles > 0 else 0\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluate_model(student_model, dataloader, student_tokenizer)\n",
    "print(f\"Model accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
